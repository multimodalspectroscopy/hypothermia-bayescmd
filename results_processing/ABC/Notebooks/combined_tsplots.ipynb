{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing results using BigQuery #\n",
    "\n",
    "We start by importing all the requisite packages from BayesCMD etc. as well as ones required to plot and read data from big query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING AT: /home/buck06191/repos/Github/BayesCMD/bayescmd\n",
      " Looking for: BayesCMD\n",
      "STARTING AT: /home/buck06191/repos/Github/BayesCMD/bayescmd\n",
      " Looking for: BayesCMD\n",
      "STARTING AT: /home/buck06191/repos/Github/BayesCMD/bayescmd\n",
      " Looking for: BayesCMD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from distutils import dir_util\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import pprint\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# BayesCMD packages \n",
    "from bayescmd.results_handling import kde_plot\n",
    "from bayescmd.results_handling import scatter_dist_plot\n",
    "from bayescmd.results_handling import data_import\n",
    "from bayescmd.results_handling import plot_repeated_outputs\n",
    "from bayescmd.results_handling import histogram_plot\n",
    "from bayescmd.results_handling import data_merge_by_batch\n",
    "from bayescmd.abc import import_actual_data\n",
    "from bayescmd.abc import priors_creator\n",
    "from bayescmd.abc import get_distance\n",
    "from bayescmd.abc import inputParse\n",
    "from bayescmd.bcmdModel import ModelBCMD\n",
    "from subprocess import TimeoutExpired, CalledProcessError  # noqa\n",
    "\n",
    "# Google BigQuery\n",
    "from google.cloud import bigquery\n",
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly use service account credentials by specifying the private\n",
    "# key file. All clients in google-cloud-python have this helper.\n",
    "client = bigquery.Client.from_service_account_json(\n",
    "    \"../../gcloud/hypothermia-auth.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histogram_query(project, dataset, model, n_bins, distance):\n",
    "    histogram_query = \"\"\"\n",
    "    SELECT\n",
    "      MIN(data.{distance}) AS min,\n",
    "      MAX(data.{distance}) AS max,\n",
    "      COUNT(data.{distance}) AS num,\n",
    "      INTEGER((data.{distance}-value.min)/(value.max-value.min)*{n_bins}) AS group_\n",
    "    FROM\n",
    "      [{project}:{dataset}.{model}] data\n",
    "    CROSS JOIN (\n",
    "      SELECT\n",
    "        MAX({distance}) AS max,\n",
    "        MIN({distance}) AS min\n",
    "      FROM\n",
    "        [{project}:{dataset}.{model}]) value\n",
    "    GROUP BY\n",
    "      group_\n",
    "    ORDER BY\n",
    "      group_\n",
    "    \"\"\".format(dataset=dataset, model=model, n_bins=n_bins, distance=distance, project=project)\n",
    "    return histogram_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_posterior_query(project, dataset, model, distance, parameters, limit=50000):\n",
    "    unpacked_params = \",\\n\".join(parameters)\n",
    "    histogram_query = \"\"\"\n",
    "SELECT\n",
    "    {unpacked_params},\n",
    "    {distance},\n",
    "    idx\n",
    "FROM\n",
    "  `{project}.{dataset}.{model}`\n",
    "ORDER BY\n",
    "  {distance} ASC\n",
    "LIMIT\n",
    "  {limit}\n",
    "    \"\"\".format(project=project, dataset=dataset, model=model, unpacked_params=unpacked_params,distance=distance, limit=limit)\n",
    "    return histogram_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configuration(model_version, dataset, verbose=False):\n",
    "    current_file = Path(os.path.abspath(''))\n",
    "    config_file = os.path.join(current_file.parents[2],\n",
    "                              'config_files',\n",
    "                               'abc',\n",
    "                               'bp_hypothermia_{}'.format(model_version),\n",
    "                               'bp_hypothermia_{}_config.json'.format(model_version)\n",
    "                              )\n",
    "\n",
    "    with open(config_file, 'r') as conf_f:\n",
    "        conf = json.load(conf_f)\n",
    "\n",
    "    params = conf['priors']\n",
    "\n",
    "    input_path = os.path.join(current_file.parents[2],\n",
    "                              'data',\n",
    "                              'clean_hypothermia',\n",
    "                              '{}_filtered_formatted.csv'.format(dataset.upper()))\n",
    "\n",
    "    d0 = import_actual_data(input_path)\n",
    "\n",
    "    targets = conf['targets']\n",
    "    model_name = conf['model_name']\n",
    "    inputs = conf['inputs']\n",
    "\n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"targets\": targets,\n",
    "        \"inputs\": inputs,\n",
    "        \"parameters\": params,\n",
    "        \"input_path\": input_path,\n",
    "        \"zero_flag\": conf['zero_flag'],\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        pprint(config)\n",
    "        \n",
    "    return config, d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['LWP475'])\n",
      "dict_keys(['LWP475', 'LWP479'])\n",
      "dict_keys(['LWP475'])\n",
      "dict_keys(['LWP479'])\n",
      "dict_keys(['LWP475'])\n",
      "dict_keys(['LWP479'])\n",
      "dict_keys(['LWP475'])\n",
      "dict_keys(['LWP479'])\n"
     ]
    }
   ],
   "source": [
    "configuration = {}\n",
    "\n",
    "combinations = [('0', 'LWP475'), ('0', 'LWP479'),\n",
    "                ('1', 'LWP475'), ('1_1', 'LWP479'),\n",
    "                ('2', 'LWP475'), ('2_1', 'LWP479'),\n",
    "                ('4', 'LWP475'), ('4_1', 'LWP479')]\n",
    "\n",
    "\n",
    "\n",
    "for combo in combinations:\n",
    "    \n",
    "    model_number = combo[0]\n",
    "    DATASET = combo[1]\n",
    "\n",
    "    model_name = 'bph{}'.format(model_number)\n",
    "    if model_name not in configuration.keys():\n",
    "        configuration[model_name] = {}\n",
    "\n",
    "    configuration[model_name][DATASET] = {}\n",
    "    print(configuration[model_name].keys())\n",
    "    config, d0 = load_configuration(model_number, DATASET)\n",
    "    configuration[model_name][DATASET]['bayescmd_config'] = config\n",
    "    configuration[model_name][DATASET]['original_data']= d0\n",
    "\n",
    "    configuration[model_name][DATASET]['histogram_query'] = generate_histogram_query('hypothermia-bayescmd', \n",
    "                                                                                        DATASET, \n",
    "                                                                                        model_name, \n",
    "                                                                                        100, \n",
    "                                                                                        'NRMSE')\n",
    "\n",
    "    configuration[model_name][DATASET]['posterior_query'] = generate_posterior_query('hypothermia-bayescmd', \n",
    "                                                                                        DATASET, \n",
    "                                                                                        model_name, \n",
    "                                                                                        'NRMSE', \n",
    "                                                                                        list(configuration[model_name][DATASET]['bayescmd_config']['parameters'].keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LWP475', 'LWP479'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration['bph0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class Timer(object):\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.tstart = time.time()\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        if self.name:\n",
    "            print('[%s]' % self.name,)\n",
    "        print('Elapsed: %s' % (time.time() - self.tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model):\n",
    "    \"\"\"Run a BCMD Model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : :obj:`bayescmd.bcmdModel.ModelBCMD`\n",
    "        An initialised instance of a ModelBCMD class.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : :obj:`dict`\n",
    "        Dictionary of parsed model output.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"\\tCreating input file.\")\n",
    "    model.create_initialised_input()\n",
    "    print(\"\\tModel run\")\n",
    "    model.run_from_buffer()\n",
    "    print(\"\\tParse output\")\n",
    "    output = model.output_parse()\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_output(model_name,\n",
    "               p,\n",
    "               times,\n",
    "               input_data,\n",
    "               d0,\n",
    "               targets,\n",
    "               distance='euclidean',\n",
    "               zero_flag=None):\n",
    "    \"\"\"Generate model output and distances.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : :obj:`str`\n",
    "        Name of model\n",
    "    p : :obj:`dict`\n",
    "        Dict of form {'parameter': value} for which posteriors are being\n",
    "        investigated.\n",
    "    times : :obj:`list` of :obj:`float`\n",
    "        List of times at which the data was collected.\n",
    "    input_data : :obj:`dict`\n",
    "        Dictionary of input data as generated by :obj:`abc.inputParse`.\n",
    "    d0 : :obj:`dict`\n",
    "        Dictionary of real data, as generated by :obj:`abc.import_actual_data`.\n",
    "    targets : :obj:`list` of :obj:`str`\n",
    "        List of model outputs against which the model is being optimised.\n",
    "    distance : :obj:`str`\n",
    "        Distance measure. One of 'euclidean', 'manhattan', 'MAE', 'MSE'.\n",
    "    zero_flag : dict\n",
    "        Dictionary of form target(:obj:`str`): bool, where bool indicates\n",
    "        whether to zero that target.\n",
    "\n",
    "        Note: zero_flag keys should match targets list.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    :obj:`tuple`\n",
    "        A tuple of (p, model output data).\n",
    "\n",
    "    \"\"\"\n",
    "    _model = ModelBCMD(\n",
    "        model_name, inputs=input_data, params=p, times=times, outputs=targets)\n",
    "\n",
    "    output = run_model(_model)\n",
    "    \n",
    "    del _model\n",
    "    \n",
    "\n",
    "    print(\"Getting distances\")\n",
    "    dist = get_distance(\n",
    "        d0,\n",
    "        output,\n",
    "        targets,\n",
    "        distance=distance.split(\"_\")[-1],\n",
    "        zero_flag=zero_flag)\n",
    "\n",
    "    try:\n",
    "        for k, v in dist.items():\n",
    "            p[k] = v\n",
    "    except AttributeError as e:\n",
    "        print(\"Error in finding distance.\\n dist is {}:\".format(dist))\n",
    "        pprint.pprint(p)\n",
    "        pprint.pprint(output)\n",
    "\n",
    "        raise e\n",
    "\n",
    "    if zero_flag:\n",
    "        for k, boolean in zero_flag.items():\n",
    "            if boolean:\n",
    "                output[k] = [x - output[k][0] for x in output[k]]\n",
    "    return p, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repeated_outputs(df,\n",
    "                          model_name,\n",
    "                          parameters,\n",
    "                          input_path,\n",
    "                          inputs,\n",
    "                          targets,\n",
    "                          n_repeats,\n",
    "                          zero_flag,\n",
    "                          tolerance=None,\n",
    "                          limit=None,\n",
    "                          frac=None,\n",
    "                          openopt_path=None,\n",
    "                          offset=None,\n",
    "                          distance='euclidean'):\n",
    "    \"\"\"Generate model output and distances multiple times.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : :obj:`str`\n",
    "        Names of model. Should match the modeldef file for model being generated\n",
    "        i.e. model_name of 'model`' should have a modeldef file\n",
    "        'model1.modeldef'.\n",
    "    parameters : :obj:`dict` of :obj:`str`: :obj:`tuple`\n",
    "        Dict of model parameters to compare, with value tuple of the prior max\n",
    "        and min.\n",
    "    input_path : :obj:`str`\n",
    "        Path to the true data file\n",
    "    inputs : :obj:`list` of :obj:`str`\n",
    "        List of model inputs.\n",
    "    targets : :obj:`list` of :obj:`str`\n",
    "        List of model outputs against which the model is being optimised.\n",
    "    n_repeats : :obj: `int`\n",
    "        Number of times to generate output data\n",
    "    frac : :obj:`float`\n",
    "        Fraction of results to consider. Should be given as a percentage i.e.\n",
    "        1=1%, 0.1=0.1%\n",
    "    zero_flag : dict\n",
    "        Dictionary of form target(:obj:`str`): bool, where bool indicates\n",
    "        whether to zero that target.\n",
    "\n",
    "        Note: zero_flag keys should match targets list.\n",
    "    openopt_path : :obj:`str` or :obj:`None`\n",
    "        Path to the openopt data file if it exists. Default is None.\n",
    "    offset : :obj:`dict`\n",
    "        Dictionary of offset parameters if they are needed\n",
    "    distance : :obj:`str`, optional\n",
    "        Distance measure. One of 'euclidean', 'manhattan', 'MAE', 'MSE'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig : :obj:`matplotlib.figure`\n",
    "        Figure containing all axes.\n",
    "\n",
    "    \"\"\"\n",
    "    p_names = list(parameters.keys())\n",
    "    sorted_df = df.sort_values(by=distance)\n",
    "\n",
    "    if tolerance:\n",
    "        accepted_limit = sum(df[distance].values < tolerance)\n",
    "    elif limit:\n",
    "        accepted_limit = limit\n",
    "    elif frac:\n",
    "        accepted_limit = frac_calculator(sorted_df, frac)\n",
    "    else:\n",
    "        raise ValueError('No limit or fraction given.')\n",
    "\n",
    "    df_list=[]\n",
    "    if n_repeats > accepted_limit:\n",
    "        print(\n",
    "            \"Setting number of repeats to quarter of the posterior size\\n\",\n",
    "            file=sys.stderr)\n",
    "        n_repeats = int(accepted_limit / 4)\n",
    "    d0 = import_actual_data(input_path)\n",
    "    input_data = inputParse(d0, inputs)\n",
    "\n",
    "    true_data = pd.read_csv(input_path)\n",
    "    times = true_data['t'].values\n",
    "\n",
    "    if openopt_path:\n",
    "        openopt_data = pd.read_csv(openopt_path)\n",
    "\n",
    "    if n_repeats > accepted_limit:\n",
    "        raise ValueError(\n",
    "            \"Number of requested model runs greater than posterior size:\"\n",
    "            \"\\n\\tPosterior Size: {}\\n\\tNumber of runs: {}\".format(\n",
    "                accepted_limit, n_repeats))\n",
    "        \n",
    "    \n",
    "\n",
    "    rand_selection = list(range(accepted_limit))\n",
    "    random.shuffle(rand_selection)\n",
    "\n",
    "    outputs_list = []\n",
    "\n",
    "\n",
    "    posteriors = sorted_df.iloc[:accepted_limit][p_names].values\n",
    "    select_idx = 0\n",
    "    with Timer(\"Getting outputs\"):\n",
    "        while len(outputs_list) < n_repeats:\n",
    "            try:\n",
    "                idx = rand_selection.pop()\n",
    "                p = dict(zip(p_names, posteriors[idx]))\n",
    "                if offset:\n",
    "                    p = {**p, **offset}\n",
    "                print(\"Sample {}, idx:{}\".format(len(outputs_list), idx))\n",
    "                now = datetime.datetime.now()\n",
    "                print(now.strftime(\"%H:%M:%S\"))\n",
    "                output = get_output(\n",
    "                    model_name,\n",
    "                    p,\n",
    "                    times,\n",
    "                    input_data,\n",
    "                    d0,\n",
    "                    targets,\n",
    "                    distance=distance,\n",
    "                    zero_flag=zero_flag)\n",
    "                outputs_list.append(output)\n",
    "\n",
    "\n",
    "            except (TimeoutError, TimeoutExpired) as e:\n",
    "                print(\"Timed out for Sample {}, idx:{}\".format(\n",
    "                    len(outputs_list), idx))\n",
    "                pprint.pprint(p)\n",
    "                rand_selection.insert(0, idx)\n",
    "            except (CalledProcessError) as e:\n",
    "                print(\"CalledProcessError for Sample {}, idx:{}\".format(\n",
    "                    len(outputs_list), idx))\n",
    "                pprint.pprint(p)\n",
    "                rand_selection.insert(0, idx)\n",
    "\n",
    "    d = {\"Errors\": {}, \"Outputs\": {}}\n",
    "\n",
    "    with Timer('Getting means'):\n",
    "        d['Errors']['Average'] = np.nanmean([o[0]['TOTAL'] for o in outputs_list])\n",
    "        for target in targets:\n",
    "            d['Errors'][target] = np.nanmean([o[0][target] for o in outputs_list])\n",
    "            d['Outputs'][target] = [o[1][target] for o in outputs_list]\n",
    "\n",
    "    \n",
    "    for ii, target in enumerate(targets):\n",
    "        x = [j for j in times for n in range(len(d['Outputs'][target]))]\n",
    "        with Timer('Transposing {}'.format(target)):\n",
    "            print(d['Outputs'][target])\n",
    "            y = np.array(d['Outputs'][target]).transpose().flatten()\n",
    "        model_name = [model_name]*len(x)\n",
    "        target = [target]*len(x)\n",
    "        df_list.append(pd.DataFrame({\"Time\": x, \"Posterior\": y, \"Model Name\": model_name, \"Output\": target}))\n",
    "\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on bph1 - LWP475\n",
      "\tRunning SQL query\n",
      "\tGetting Posterior Predictive\n",
      "Sample 0, idx:2134\n",
      "17:04:32\n",
      "TEMP DIR:  /tmp/bp_hypothermiazyd4oadw\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n",
      "Closing f_err\n",
      "RADAU5: computation successful\n",
      "\n",
      "Decoding output!\n",
      "\tParse output\n",
      "Deleting model.\n",
      "Getting distances\n",
      "Sample 1, idx:9161\n",
      "17:04:34\n",
      "TEMP DIR:  /tmp/bp_hypothermia3vg7vl1q\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n",
      "Closing f_err\n",
      "RADAU5: computation successful\n",
      "\n",
      "Decoding output!\n",
      "\tParse output\n",
      "Deleting model.\n",
      "Getting distances\n",
      "Sample 2, idx:42230\n",
      "17:04:35\n",
      "TEMP DIR:  /tmp/bp_hypothermiab2bdis28\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n",
      "Closing f_err\n",
      "RADAU5: computation successful\n",
      "\n",
      "Decoding output!\n",
      "\tParse output\n",
      "Deleting model.\n",
      "Getting distances\n",
      "Sample 3, idx:12103\n",
      "17:04:36\n",
      "TEMP DIR:  /tmp/bp_hypothermiatip9f4bu\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n",
      "Closing f_err\n",
      "RADAU5: computation successful\n",
      "\n",
      "Decoding output!\n",
      "\tParse output\n",
      "Deleting model.\n",
      "Getting distances\n",
      "Sample 4, idx:36436\n",
      "17:04:37\n",
      "TEMP DIR:  /tmp/bp_hypothermiahy4_r58q\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n",
      "Closing f_err\n",
      "RADAU5: computation successful\n",
      "\n",
      "Decoding output!\n",
      "\tParse output\n",
      "Deleting model.\n",
      "Getting distances\n",
      "Sample 5, idx:16445\n",
      "17:04:38\n",
      "TEMP DIR:  /tmp/bp_hypothermia8jy337st\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n",
      "Closing f_err\n",
      "RADAU5: computation successful\n",
      "\n",
      "Decoding output!\n",
      "\tParse output\n",
      "Deleting model.\n",
      "Getting distances\n",
      "Sample 6, idx:34152\n",
      "17:04:39\n",
      "TEMP DIR:  /tmp/bp_hypothermianb64jm4i\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n",
      "Closing f_err\n",
      "RADAU5: computation successful\n",
      "\n",
      "Decoding output!\n",
      "\tParse output\n",
      "Deleting model.\n",
      "Getting distances\n",
      "Sample 7, idx:14588\n",
      "17:04:40\n",
      "TEMP DIR:  /tmp/bp_hypothermiaw4fzojeo\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n",
      "Closing f_err\n",
      "RADAU5: computation successful\n",
      "\n",
      "Decoding output!\n",
      "\tParse output\n",
      "Deleting model.\n",
      "Getting distances\n",
      "Sample 8, idx:870\n",
      "17:04:41\n",
      "TEMP DIR:  /tmp/bp_hypothermia9g3anu81\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n",
      "Closing f_err\n",
      "RADAU5: computation successful\n",
      "\n",
      "Decoding output!\n",
      "\tParse output\n",
      "Deleting model.\n",
      "Getting distances\n",
      "Sample 9, idx:7194\n",
      "17:04:42\n",
      "TEMP DIR:  /tmp/bp_hypothermiag7cl77k4\n",
      "BASEDIR set to ../../../../BayesCMD\n",
      "\tCreating input file.\n",
      "\tModel run\n",
      "Running model.\n",
      "['buffer_bp_hypothermia.stderr']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "labels = {\"t\": \"Time (sec)\",\n",
    "              \"SaO2sup\": \"SaO2 (%)\",\n",
    "              \"P_a\": \"ABP (mmHg)\",\n",
    "              \"temp\": \"Temperature ($^{\\circ}$C)\",\n",
    "               \"TOI\": \"TOI (%)\",\n",
    "              \"HbO2\": \"$\\Delta$HbO$_2$ $(\\mu M)$\",\n",
    "              \"HHb\": \"$\\Delta$HHb $(\\mu M)$\",\n",
    "              \"CCO\": \"$\\Delta$CCO $(\\mu M)$\"\n",
    "             }\n",
    "LIM=50000\n",
    "combinations = [('bph0', 'LWP475'), ('BPH0', 'LWP479'),\n",
    "                ('bph1', 'LWP475'), ('bph1_1', 'LWP479'),\n",
    "                ('bph2', 'LWP475'), ('bph2_1', 'LWP479'),\n",
    "                ('bph4', 'LWP475'), ('bph4_1', 'LWP479')]\n",
    "\n",
    "\n",
    "signals = ['CCO', 'HbO2', 'HHb']\n",
    "\n",
    "# for fig_num, combo in enumerate(combinations):\n",
    "#     DATASET=combo[1]\n",
    "#     model_name=combo[0]\n",
    "model_names = ['bph1', 'bph2', 'bph4']\n",
    "df_dict = {k:None for k in model_names}\n",
    "for model_name in model_names:\n",
    "    DATASET=\"LWP475\"\n",
    "    print(\"Working on {} - {}\".format(model_name, DATASET))\n",
    "    # Set config and create figure path\n",
    "    config = configuration[model_name][DATASET]['bayescmd_config']\n",
    "    figPath = \"/home/buck06191/Dropbox/phd/hypothermia/ABC/Figures/{}/{}/{}\".format(model_name, DATASET, 'NRMSE')\n",
    "    dir_util.mkpath(figPath)\n",
    "\n",
    "    # Get posterior\n",
    "    print(\"\\tRunning SQL query\")\n",
    "    df_post = client.query(configuration[model_name][DATASET]['posterior_query']).to_dataframe()\n",
    "\n",
    "\n",
    "    # Plot posterior predictive\n",
    "    config[\"offset\"] = {}\n",
    "    print(\"\\tGetting Posterior Predictive\")\n",
    "    df_list = get_repeated_outputs(df_post, n_repeats=1, limit=LIM,\n",
    "                                    distance='NRMSE', **config)\n",
    "    df_dict[model_name] = df_list\n",
    "#     for ix, ax in enumerate(axes.flatten()):\n",
    "#         ax.set_ylabel(labels[signals[ix]])\n",
    "#         old_title = ax.get_title().split(':')\n",
    "#         new_title = \":\".join([labels[signals[ix]].split()[0], old_title[1]])\n",
    "#         ax.set_title(new_title, size=11)\n",
    "#     axes.flatten()[-1].set_xlabel(labels['t'])\n",
    "#     fig.suptitle(string.ascii_lowercase[fig_num]+\")\", ha='left', x=-0.02, y=0.925)\n",
    "    #fig.set_size_inches(18.5, 12.5)\n",
    "#     with open(os.path.join(figPath, 'posterior_predictive_{}_{}.pickle'.format(model_name, DATASET)), 'wb') as f: \n",
    "#         pickle.dump(fig, f)\n",
    "#     fig.savefig(\n",
    "#         os.path.join(figPath, 'posterior_predictive_{}_{}.png'\n",
    "#                      .format(model_name, DATASET)),\n",
    "#         bbox_inches='tight', bbox_extra_artists=(lgd,), dpi=250)\n",
    "#     plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
